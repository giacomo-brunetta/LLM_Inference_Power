Model Name,FrameWork,Hardware type,Count,Precision,Batch Size,In tokens,Out tokens,TTFT,Latency
meta-llama/Llama-2-7b-hf,Transformers,NVIDIA A100-PCIE-40GB,1,torch.float16,32,128,128,369.8715409263969,6.422036296920851
meta-llama/Llama-2-7b-hf,Transformers,NVIDIA A100-PCIE-40GB,1,torch.float16,32,128,128,372.19762592576444,6.061966377776116
